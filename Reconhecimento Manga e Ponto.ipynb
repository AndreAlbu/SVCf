{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rede Neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/my_ssd_mobnet/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/my_ssd_mobnet/'\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import os\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "CUSTOM_MODEL_NAME = 'my_ssd_mobnet' \n",
    "CONFIG_PATH = MODEL_PATH+'/'+CUSTOM_MODEL_NAME+'/pipeline.config'\n",
    "\n",
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "\n",
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEFINI VARIÁVEIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicia_variaveis():\n",
    "    \n",
    "    global tempoInicialGeral, tempoFinalGeral, identificadas, baixo, alto, fator_imgs, altura_minima_ponto, altura_maxima_ponto\n",
    "    global corretas, erradas, info, sensibilidade, mediaHistograma, LER_IMG, ESCREVE_IMG, distancia_pontos_raio_px, delta_distancia_lidar, reducao_caixa_fruta\n",
    "    \n",
    "    global TIPO_BASE, limiarLarguraPedunculo, limiarAlturaPedunculo, NOME_IMAGEM, NOME_JSON, NOME_TXT, METODO, min_samples,metodo_pontos_curva,altura_caixa_pedunculo\n",
    "    \n",
    "    tempoInicialGeral = 0\n",
    "    tempoFinalGeral = 0\n",
    "    identificadas = 0\n",
    "    \n",
    "    corretas =        []\n",
    "    erradas =         []\n",
    "    info =            []\n",
    "    sensibilidade =   []\n",
    "    mediaHistograma = []\n",
    "\n",
    "    limiarAlturaPedunculo  = 0.3\n",
    "    limiarLarguraPedunculo = 0.2\n",
    "\n",
    "    baixo = [2, 0, 0]\n",
    "    alto  = [25, 255, 255]\n",
    "\n",
    "    distancia_pontos_raio_px = 2\n",
    "\n",
    "    fator_imgs = 7.5\n",
    "    \n",
    "    altura_minima_ponto = 3\n",
    "    altura_maxima_ponto = 8\n",
    "    \n",
    "    delta_distancia_lidar = 10\n",
    "    \n",
    "    reducao_caixa_fruta = 0.2\n",
    "    \n",
    "    altura_caixa_pedunculo = 10\n",
    "    \n",
    "    min_samples = 4\n",
    "    metodo_pontos_curva = \"IsolationForest\"\n",
    "    #metodo_pontos_curva = \"Outliners\"\n",
    "    \n",
    "    TIPO_BASE = \"3D\"\n",
    "    \n",
    "    METODO = \"DBSCAN\"\n",
    "    #METODO = \"Kmeans\"\n",
    "    #METODO = \"Heuristica\"\n",
    "    \n",
    "    #NOME_IMAGEM = \"_MANGO_LEAFLESS\"\n",
    "    #NOME_JSON   = \"_MANGO_MAP_JSON\"\n",
    "    \n",
    "    #PASTA = \"VALID_CUT_POINT_2D/\"\n",
    "    #LER_IMG = \"VI2D_MANGO_LEAFLESS/\"\n",
    "    \n",
    "    NOME_IMAGEM = \"_MANGO_IMAGE\"\n",
    "    NOME_JSON   = \"_MANGO_MAP_JSON\"\n",
    "    \n",
    "    PASTA = \"VALID_LIDAR_IMAGES_3D/\"\n",
    "    LER_IMG = \"VALIDACAO_SVCF/\"\n",
    "    \n",
    "    LER_IMG = PASTA + LER_IMG\n",
    "    ESCREVE_IMG = \"RESULTADO_IMAGENS_VALIDACAO_3D/\"\n",
    "    \n",
    "    NOME_TXT = LER_IMG[:-1] + \"_\" + TIPO_BASE + \"_\" + METODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNÇÃO PRINCIPAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "import time\n",
    "import traceback\n",
    "import math\n",
    "import json\n",
    "import os\n",
    "\n",
    "import PC_SVCF as pc\n",
    "import Lidar as lidar\n",
    "import Valida_SVCF as vl\n",
    "\n",
    "inicia_variaveis()\n",
    "\n",
    "print(\"Executando...\")\n",
    "print(\"Log...\" + NOME_TXT)\n",
    "arquivo = open(NOME_TXT + \".csv\", \"w\")\n",
    "\n",
    "if(TIPO_BASE == \"2D\"):\n",
    "    \n",
    "    arquivo.write(\"IMAGEM,ID_MANGA,SCORES,HUE,%_MANGA,%_PONTO,MEDIA\\n\")\n",
    "    \n",
    "    tamanhoLetraTexto = 0.6\n",
    "    fatorLetra = 20\n",
    "    \n",
    "else:\n",
    "    \n",
    "    arquivo.write(\"IMAGEM,ID_MANGA,SCORES,FATOR_CM_PX,DISTÂNCIA_MANGA,HUE,DISTÂNCIA_PONTO,%_MANGA,%_PEDÚNCULO,DISTÂNCIA HORI,%_PONTO,MEDIA\\n\")\n",
    "    \n",
    "    tamanhoLetraTexto = 1.0\n",
    "    fatorLetra = 35\n",
    "\n",
    "tempoInicialGeral = time.time()\n",
    "\n",
    "id_imagem = 1\n",
    "qtdImage  = 72\n",
    "\n",
    "pontosJson = \"\"\n",
    "fator_cm_px = \"\"\n",
    "\n",
    "while(id_imagem <= qtdImage):\n",
    "    \n",
    "    inicia_variaveis()\n",
    "\n",
    "    print(\"############## CONFIGURAÇÕES DE LEITURA DOS ARQUIVOS ######################\\n\")\n",
    "    \n",
    "    caminho_imagem = LER_IMG + str(id_imagem) + NOME_IMAGEM +  \".jpg\"\n",
    "    print(f\"Caminho da imagem: {caminho_imagem}\")\n",
    "    \n",
    "    imagem_original = cv2.imread(LER_IMG + str(id_imagem) + NOME_IMAGEM + \".jpg\")\n",
    "        \n",
    "    caminho_json = LER_IMG + str(id_imagem) + NOME_JSON + \".json\"\n",
    "    print(f\"Caminho do json:   {caminho_json}\\n\")\n",
    "    \n",
    "    if(TIPO_BASE == \"3D\"):\n",
    "\n",
    "        pontosJson = lidar.organizaJSON(caminho_json)\n",
    "        \n",
    "    #Copia a imagem original\n",
    "    imagem_original_copia = np.array(imagem_original)\n",
    "    \n",
    "    imagem_detectada = imagem_original_copia.copy() #USADA DURANTE A EXECUÇÃO DO CÓDIGO\n",
    "    imagem_pedunculo = imagem_original_copia.copy() #USADA PARA A ÁREA DO PEDÚNCULO\n",
    "    \n",
    "    #Copia a imagem na versão reduzida\n",
    "    imagem_original_reduzida_aux = cv2.resize(imagem_original, (192, 256))\n",
    "    imagem_original_reduzida = np.array(imagem_original_reduzida_aux.astype(np.uint8))\n",
    "    \n",
    "    ################################ CONFIGURAÇÕES DA REDE NEURAL ################################\n",
    "    \n",
    "    category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+'/label_map.pbtxt')\n",
    "        \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(imagem_original_copia, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor) \n",
    "\n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    \n",
    "    detection_threshold = 0.8\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                imagem_detectada,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes'] + label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                skip_scores= True,\n",
    "                skip_labels= True,\n",
    "                skip_boxes= False,\n",
    "                agnostic_mode=False)\n",
    "  \n",
    "    scores = list(filter(lambda x: x> detection_threshold, \n",
    "    detections['detection_scores']))\n",
    "    boxes = detections['detection_boxes'][:len(scores)]\n",
    "    classes = detections['detection_classes'][:len(scores)]\n",
    "        \n",
    "    width =  imagem_detectada.shape[1]\n",
    "    height = imagem_detectada.shape[0]\n",
    "        \n",
    "    sensibilidade.append(scores)\n",
    "    \n",
    "    quantidade_fruta_identificadas = len(scores)\n",
    "    \n",
    "    ################################ INICIO DO PROCESSO DE LOCALIZAÇÃO DO PONTO DE CORTE ################################\n",
    "    \n",
    "    if(quantidade_fruta_identificadas > 0):\n",
    "                \n",
    "        print(f\"Imagem: {id_imagem} - Quantidade de fruta identificada: {quantidade_fruta_identificadas}\\n\")\n",
    "                \n",
    "        try:\n",
    "            \n",
    "            posicaoTextoY = fatorLetra\n",
    "            \n",
    "            for id_manga_localizada, box in enumerate(boxes):\n",
    "                \n",
    "                arquivo.write(f\"{str(id_imagem)},\")\n",
    "                                \n",
    "                print(f\"Manga localizada: {id_manga_localizada}\")\n",
    "                \n",
    "                if(id_manga_localizada < 2):\n",
    "                    \n",
    "                    arquivo.write(f\"{str(id_manga_localizada)},\")\n",
    "                    arquivo.write(f\"{str(round(scores[id_manga_localizada], 4))},\")\n",
    "                                                            \n",
    "                    ################################# ÁREA DA MANGA #################################\n",
    "\n",
    "                    roi = box * [height, width, height, width]\n",
    "                    \n",
    "                    xt_ia_manga = roi[1]\n",
    "                    yt_ia_manga = roi[0]\n",
    "                    \n",
    "                    xb_ia_manga = roi[3]\n",
    "                    yb_ia_manga = roi[2]\n",
    "\n",
    "                    xt_ia_manga = int(xt_ia_manga)\n",
    "                    xb_ia_manga = int(xb_ia_manga)\n",
    "                    yt_ia_manga = int(yt_ia_manga)\n",
    "                    yb_ia_manga = int(yb_ia_manga)\n",
    "                    \n",
    "                    cv2.putText(imagem_detectada, str(id_manga_localizada), (xt_ia_manga, yt_ia_manga - 5), cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "                                        \n",
    "                    centroCaixaFrutaX = int((xt_ia_manga + xb_ia_manga) / 2)\n",
    "                    centroCaixaFrutaY = int((yt_ia_manga + yb_ia_manga) / 2)\n",
    "                    \n",
    "                    centroCaixaFrutaXLidar = int(centroCaixaFrutaX / fator_imgs)\n",
    "                    centroCaixaFrutaYLidar = int(centroCaixaFrutaY / fator_imgs)\n",
    "                    \n",
    "                    media_imagem = [ ]\n",
    "                    \n",
    "                    if(TIPO_BASE == \"3D\"):\n",
    "                    \n",
    "                        #Função para encontrar o fator cm_px referente a manga\n",
    "                        fator_cm_px = pc.obter_cm_px(4, 2, centroCaixaFrutaXLidar, centroCaixaFrutaYLidar, pontosJson)\n",
    "                                                \n",
    "                        arquivo.write(f\"{str(round(fator_cm_px, 4))},\")\n",
    "\n",
    "                        print(f\"Fator cm_px: {fator_cm_px:.5f}\")\n",
    "                                            \n",
    "                        altura_caixa_pedunculo = 2.5 / fator_cm_px * fator_imgs\n",
    "\n",
    "                        distanciaFruta = lidar.measureDistanceOnePoint((centroCaixaFrutaXLidar, centroCaixaFrutaYLidar), pontosJson)\n",
    "\n",
    "                        print(f\"Distancia Manga: {distanciaFruta:.2f} cm\")\n",
    "                        \n",
    "                        arquivo.write(f\"{str(round(distanciaFruta, 2))},\")\n",
    "\n",
    "                        \n",
    "                    #Faz um corte na área da manga\n",
    "                    areaManga = imagem_detectada[yt_ia_manga:yb_ia_manga, xt_ia_manga:xb_ia_manga]\n",
    "                    \n",
    "                    #Circulo no centro da área da manga\n",
    "                    cv2.circle(imagem_detectada, (int(centroCaixaFrutaX), int(centroCaixaFrutaY)), 5, (255, 0, 90), -1)\n",
    "                    \n",
    "                    #Desenha um retangulo na área da manga\n",
    "                    cv2.rectangle(imagem_detectada, (xt_ia_manga, yt_ia_manga), (xb_ia_manga, yb_ia_manga), (255,0,0), 2)\n",
    "                    \n",
    "                    \n",
    "                    ################################# ÁREA DO PEDÚNCULO ################################# \n",
    "\n",
    "                    #Chama a função que prevê a área do pedúnculo\n",
    "                    areaPedunculo = pc.preveAreaPedunculo(xt_ia_manga, yt_ia_manga, xb_ia_manga, yb_ia_manga, limiarLarguraPedunculo, limiarAlturaPedunculo, -altura_caixa_pedunculo)\n",
    "                    \n",
    "                    #x1                y1                 x2                 y2\n",
    "                    xt_area_pedunculo, yt_area_pedunculo, xb_area_pedunculo, yb_area_pedunculo = areaPedunculo[0], areaPedunculo[1], areaPedunculo[2], areaPedunculo[3]\n",
    "\n",
    "                    #Desenha um retangulo na área do pedúnculo        \n",
    "                    cv2.rectangle(imagem_detectada, (xt_area_pedunculo, yt_area_pedunculo), (xb_area_pedunculo, yb_area_pedunculo), (0, 0, 255), 2)\n",
    "\n",
    "                    #Coordenadas da área da manga\n",
    "                    TopLeftX = xt_area_pedunculo\n",
    "                    TopLeftY = yb_area_pedunculo\n",
    "\n",
    "                    #Faz o corte na área prevista do pedúnculo\n",
    "                    corteAreaPedunculo = imagem_pedunculo[yb_area_pedunculo:yt_area_pedunculo, xt_area_pedunculo:xb_area_pedunculo]                    \n",
    "                    \n",
    "                    if(len(corteAreaPedunculo) < 1):\n",
    "                        \n",
    "                        print(\"Área do pedúnculo muito pequena\")\n",
    "                        \n",
    "                    else:\n",
    "                    \n",
    "                        #Circulo no centro do topo da área da fruta\n",
    "                        cv2.circle(imagem_detectada, (int(centroCaixaFrutaX), int(yt_ia_manga)), 5, (0, 0, 255), -1)\n",
    "\n",
    "                        if(TIPO_BASE == \"3D\"):\n",
    "\n",
    "                            #Distancia do centro do topo da caixa do fruta\n",
    "                            distanciaTopoCaixaFruto = lidar.measureDistanceOnePoint((centroCaixaFrutaXLidar, int(yt_ia_manga / fator_imgs)), pontosJson)\n",
    "\n",
    "                            print(f\"Distancia Topo Caixa: {distanciaTopoCaixaFruto:.2f} cm\")\n",
    "\n",
    "                        #Função que encontra o ponto de corte final de acordo com os parâmetros\n",
    "                        ponto_final = pc.localiza_ponto_final(str(id_imagem),\n",
    "                                                str(id_manga_localizada),\n",
    "                                                corteAreaPedunculo, \n",
    "                                                baixo, \n",
    "                                                alto, \n",
    "                                                METODO, \n",
    "                                                ESCREVE_IMG, \n",
    "                                                True, \n",
    "                                                \"top\", \n",
    "                                                7, \n",
    "                                                min_samples, \n",
    "                                                TIPO_BASE, \n",
    "                                                metodo_pontos_curva, \n",
    "                                                TopLeftX, \n",
    "                                                TopLeftY, \n",
    "                                                pontosJson, \n",
    "                                                altura_minima_ponto, \n",
    "                                                (centroCaixaFrutaX, centroCaixaFrutaY), \n",
    "                                                (centroCaixaFrutaX, yt_ia_manga))\n",
    "\n",
    "                        pontoX, pontoY, valorHue, distanciaPonto = ponto_final[0], ponto_final[1], ponto_final[2], ponto_final[3]\n",
    "\n",
    "                        arquivo.write(f\"{str(valorHue)},\")\n",
    "\n",
    "                        cv2.circle(imagem_detectada, (pontoX, pontoY), 5, (255, 0, 255), -1)\n",
    "                        cv2.line(imagem_detectada, (pontoX, pontoY), (centroCaixaFrutaX, yt_ia_manga), (255, 0, 255), 3)\n",
    "                        cv2.circle(imagem_detectada, (pontoX, pontoY), 6, (255, 0, 0), 2)\n",
    "\n",
    "                        #Função para validar o sistema\n",
    "                        validacao = vl.valida_svcf(imagem_detectada, \n",
    "                                       None,\n",
    "                                       id_imagem,\n",
    "                                       id_manga_localizada,\n",
    "                                       TIPO_BASE,\n",
    "                                       (xt_ia_manga, yt_ia_manga, xb_ia_manga, yb_ia_manga),\n",
    "                                       (xt_area_pedunculo, yt_area_pedunculo, xb_area_pedunculo, yb_area_pedunculo),\n",
    "                                       caminho_json, \n",
    "                                       fator_cm_px,\n",
    "                                       (pontoX, pontoY),\n",
    "                                       altura_minima_ponto,\n",
    "                                       distanciaPonto)\n",
    "\n",
    "                        por_manga, por_pedunculo, por_ponto, distancia_hor = validacao[0], validacao[1], validacao[2], validacao[3]\n",
    "\n",
    "                        if(TIPO_BASE == \"3D\"):\n",
    "\n",
    "                            arquivo.write(f\"{str(round(distanciaPonto, 2))},\")\n",
    "\n",
    "                        arquivo.write(f\"{str(por_manga)},\")\n",
    "\n",
    "                        print(f\"Porcentagem Manga:     {por_manga} %\")\n",
    "                        cv2.putText(imagem_detectada, \"Precisao Manga - \" + str(id_manga_localizada) + \": \"+ str(por_manga) + \" %\", (20, posicaoTextoY),cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "\n",
    "                        posicaoTextoY += fatorLetra\n",
    "\n",
    "                        if(por_pedunculo != -1):\n",
    "\n",
    "                            print(f\"Porcentagem Pedunculo: {por_pedunculo} %\")\n",
    "                            print(f\"Distancia Horizontal:  {distancia_hor} cm\")\n",
    "\n",
    "                            arquivo.write(f\"{str(por_pedunculo)},\")\n",
    "                            arquivo.write(f\"{str(distancia_hor)},\")\n",
    "\n",
    "                            cv2.putText(imagem_detectada,\"Precisao Pedunculo: \" + str(por_pedunculo) + \" %\", (20, posicaoTextoY),cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "\n",
    "                            posicaoTextoY += fatorLetra\n",
    "\n",
    "                            cv2.putText(imagem_detectada, \"Distancia Hor: \" + str(distancia_hor) + \" cm\", (20, posicaoTextoY), cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "\n",
    "                            posicaoTextoY += fatorLetra\n",
    "\n",
    "                        arquivo.write(f\"{str(por_ponto)},\")\n",
    "                        print(f\"Porcentagem Ponto:     {por_ponto} %\")\n",
    "                        cv2.putText(imagem_detectada, \"Precisao Ponto: \" + str(por_ponto) + \" %\", (20, posicaoTextoY), cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "\n",
    "                        posicaoTextoY += fatorLetra\n",
    "\n",
    "                        if(TIPO_BASE == \"3D\"):\n",
    "\n",
    "                            media_imagem = [por_manga, por_pedunculo, por_ponto]\n",
    "\n",
    "                            cv2.putText(imagem_detectada, \"Altura Ponto: \" + str(distanciaPonto) + \" cm\", (20, posicaoTextoY), cv2.FONT_HERSHEY_SIMPLEX, tamanhoLetraTexto, (0, 0, 255), 2, 1)\n",
    "\n",
    "                            posicaoTextoY += fatorLetra + 15\n",
    "\n",
    "                        else:\n",
    "\n",
    "                            media_imagem = [por_manga, por_ponto]\n",
    "\n",
    "                        arquivo.write(f\"{str(round(np.mean(media_imagem), 2))}\\n\")\n",
    "                        \n",
    "                        #Salva imagem representativa da calibração\n",
    "                        cv2.imwrite(ESCREVE_IMG + str(id_imagem) + \"_\" + str(id_manga_localizada) + \"_a_calibracao.png\", imagem_original_reduzida)\n",
    "                        \n",
    "                        #Salva imagem da área do pedúnculo RGB\n",
    "                        cv2.imwrite(ESCREVE_IMG + str(id_imagem) + \"_\" + str(id_manga_localizada) + \"_b_area_pedunculo.jpg\", corteAreaPedunculo)\n",
    "\n",
    "             \n",
    "                cv2.imwrite(ESCREVE_IMG + str(id_imagem) + \"_\" + str(id_manga_localizada) + \"_j_ponto_final.jpg\", imagem_detectada)\n",
    "                    \n",
    "            print(\"-*-*-*-*-*-*-*-*-*-*-*\")\n",
    "                        \n",
    "            id_imagem = id_imagem + 1\n",
    "                  \n",
    "        except:\n",
    "\n",
    "            print(f\"{id_imagem} - Erro desconhecido\\n\") \n",
    "            \n",
    "            traceback.print_exc()\n",
    "\n",
    "            id_imagem = id_imagem + 1\n",
    "            \n",
    "    else:\n",
    "        \n",
    "        print(\"\\n{} - Fruta nao identificada\\n\".format(id_imagem))\n",
    "        \n",
    "        id_imagem = id_imagem + 1\n",
    "        \n",
    "tempoFinalGeral = time.time()\n",
    "\n",
    "arquivo.close()\n",
    "print(\"\\n\\nFinalizando...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
